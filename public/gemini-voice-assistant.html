<!DOCTYPE html>
<html>
<head>
    <title>Gemini Voice Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
        }
        .button-container {
            margin: 20px 0;
        }
        button {
            padding: 12px 24px;
            font-size: 16px;
            margin: 0 10px;
            cursor: pointer;
            border: none;
            border-radius: 4px;
        }
        #startBtn {
            background-color: #4CAF50;
            color: white;
        }
        #stopBtn {
            background-color: #f44336;
            color: white;
            display: none;
        }
        #status {
            margin: 20px 0;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 4px;
            min-height: 24px;
        }
        #conversation {
            text-align: left;
            margin-top: 20px;
            padding: 15px;
            background: #f9f9f9;
            border-radius: 4px;
            border: 1px solid #ddd;
            max-height: 300px;
            overflow-y: auto;
        }
        .user-message {
            color: #4285f4;
            margin: 5px 0;
        }
        .assistant-message {
            color: #0f9d58;
            margin: 5px 0;
        }
    </style>
</head>
<body>
    <h1>Gemini Voice Assistant</h1>
    <div class="button-container">
        <button id="startBtn">Start Listening</button>
        <button id="stopBtn">Stop Listening</button>
    </div>
    <div id="status">Click "Start Listening" to begin</div>
    <div id="conversation"></div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const conversationDiv = document.getElementById('conversation');
        
        // Replace with your actual Gemini API Key
        const GEMINI_API_KEY = 'YOUR_API_KEY_HERE';
        let recognition;
        let synth = window.speechSynthesis;

        function addMessageToConversation(speaker, message) {
            const messageDiv = document.createElement('div');
            messageDiv.className = speaker + '-message';
            messageDiv.textContent = `${speaker}: ${message}`;
            conversationDiv.appendChild(messageDiv);
            conversationDiv.scrollTop = conversationDiv.scrollHeight;
        }

        async function getGeminiResponse(prompt) {
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${GEMINI_API_KEY}`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        contents: [{
                            parts: [{
                                text: prompt
                            }]
                        }]
                    })
                });

                const data = await response.json();
                return data.candidates[0].content.parts[0].text;
            } catch (error) {
                console.error('Error calling Gemini API:', error);
                return "Sorry, I couldn't process your request.";
            }
        }

        function speak(text) {
            if (synth.speaking) {
                synth.cancel();
            }
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'hi-IN';
            synth.speak(utterance);
        }

        function initVoiceRecognition() {
            if (!('webkitSpeechRecognition' in window)) {
                statusDiv.textContent = 'Please use Google Chrome browser';
                startBtn.disabled = true;
                return;
            }

            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'hi-IN';

            startBtn.addEventListener('click', () => {
                recognition.start();
                statusDiv.textContent = 'Listening... Speak now';
                startBtn.style.display = 'none';
                stopBtn.style.display = 'inline-block';
            });

            stopBtn.addEventListener('click', () => {
                recognition.stop();
                statusDiv.textContent = 'Microphone off';
                startBtn.style.display = 'inline-block';
                stopBtn.style.display = 'none';
            });

            recognition.onresult = async (event) => {
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    }
                }

                if (finalTranscript) {
                    addMessageToConversation('You', finalTranscript);
                    statusDiv.textContent = 'Processing your request...';
                    
                    const response = await getGeminiResponse(finalTranscript);
                    addMessageToConversation('Assistant', response);
                    speak(response);
                    
                    statusDiv.textContent = 'Listening... Speak now';
                }
            };

            recognition.onerror = (event) => {
                statusDiv.textContent = 'Error: ' + event.error;
                startBtn.style.display = 'inline-block';
                stopBtn.style.display = 'none';
            };
        }

        initVoiceRecognition();
    </script>
</body>
</html>
